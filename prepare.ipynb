{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNCuwM4AoIx4"
      },
      "source": [
        "#### **Prepare**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XUARWywNF2tk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "prsFoiynGOFq"
      },
      "outputs": [],
      "source": [
        "## helper function for loading data\n",
        "def load_data(file_path):\n",
        "    dataset=pd.read_csv(\n",
        "        file_path,\n",
        "        sep=\"\\t\",\n",
        "        names=[\"label\", \"message\"]### add columns name\n",
        "    )\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zd5BmGUybc2y"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    #### remove duplicates rows from the dataset\n",
        "    df = df.drop_duplicates(keep=\"first\")\n",
        "    #### encode labels into integer so that the machine can understand\n",
        "    le = LabelEncoder()\n",
        "    df[\"label\"] = le.fit_transform(df[\"label\"])\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRxEyUqLo8Gj",
        "outputId": "fb7c3e21-931c-4ff2-9901-57e0a5064271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "Total no of rows=5169 and features=2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Features names are=['label', 'message']\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "Null values in each features\n",
            "label      0\n",
            "message    0\n",
            "dtype: int64\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "Data types of each features\n",
            "label       int64\n",
            "message    object\n",
            "dtype: object\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "Duplicate values in the dataset: 0\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "Data preparation completed successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1988768857.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"label\"] = le.fit_transform(df[\"label\"])\n"
          ]
        }
      ],
      "source": [
        "df=load_data(\"SMSSpamCollection\")\n",
        "df=preprocess_data(df)\n",
        "print(\"^\"*100)\n",
        "print(f\"Total no of rows={df.shape[0]} and features={df.shape[1]}\")\n",
        "print(\"-\"*100)\n",
        "print(f\"Features names are={df.columns.tolist()}\")\n",
        "print(\"^\"*100)\n",
        "### Checking for null values\n",
        "print(\"Null values in each features\")\n",
        "print(df.isnull().sum())\n",
        "print(\"^\"*100)\n",
        "print(\"Data types of each features\")\n",
        "print(df.dtypes)\n",
        "print(\"^\"*100)\n",
        "print(f\"Duplicate values in the dataset: {df.duplicated().sum()}\")\n",
        "print(\"^\"*100)\n",
        "print(\"Data preparation completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "X8Pcf26xn3yH"
      },
      "outputs": [],
      "source": [
        "def split_data(df):\n",
        "    X = df[\"message\"]\n",
        "    y = df[\"label\"]\n",
        "    #### Train split\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        X, y, test_size=0.3, stratify=y, random_state=42\n",
        "    )\n",
        "    #### Validation & Test split\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        "    )\n",
        "    train_df= pd.DataFrame({\"message\": X_train, \"label\": y_train})\n",
        "    val_df= pd.DataFrame({\"message\": X_val, \"label\": y_val})\n",
        "    test_df= pd.DataFrame({\"message\": X_test, \"label\": y_test})\n",
        "    return train_df, val_df, test_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gUeZefBYn-e-"
      },
      "outputs": [],
      "source": [
        "#### Save the dataset into csv files\n",
        "def save_splits(train_df, val_df, test_df):\n",
        "    train_df.to_csv(\"train.csv\", index=False)\n",
        "    val_df.to_csv(\"validation.csv\", index=False)\n",
        "    test_df.to_csv(\"test.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FL0FPziHpFsp"
      },
      "outputs": [],
      "source": [
        "train_df,val_df,test_df=split_data(df)\n",
        "save_splits(train_df,val_df,test_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
